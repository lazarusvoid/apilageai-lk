const micButton = document.getElementById('voicebox-micButton');
const statusEl = document.getElementById('talk-status'); // optional for status display
const transcriptEl = document.getElementById('transcript'); // optional transcript area
const assistantAudio = document.getElementById('assistant-audio');

let pc = null;
let localStream = null;
let ephemeralKey = null;
let realtimeUrl = 'https://api.openai.com/v1/realtime';
const backendUrl = 'https://talking-assitant.onrender.com';
let micActive = false;

micButton.addEventListener('click', () => {
    if (micActive) {
        stopCall();
    } else {
        startCall();
    }
    micButton.classList.toggle('active');
});

async function startCall() {
    micActive = true;
    try {
        statusEl.textContent = 'සම්බන්ධ කරමින්...';

        const sessionResp = await fetch(`${backendUrl}/session`, { method: 'POST' });
        if (!sessionResp.ok) throw new Error('session endpoint failed');
        const sessionData = await sessionResp.json();

        ephemeralKey = sessionData?.client_secret?.value || sessionData?.ephemeralKey;
        realtimeUrl = sessionData?.realtime_url || realtimeUrl;

        if (!ephemeralKey) throw new Error('no ephemeral key returned');

        localStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        pc = new RTCPeerConnection({ iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] });

        for (const track of localStream.getAudioTracks()) pc.addTrack(track, localStream);

        pc.ontrack = (ev) => {
            if (ev.streams && ev.streams[0]) {
                assistantAudio.srcObject = ev.streams[0];
                assistantAudio.play().catch(e => console.warn('play error', e));
            }
        };

        const dc = pc.createDataChannel('oai-events');
        dc.onmessage = (evt) => {
            try {
                const data = JSON.parse(evt.data);
                if (data.type === 'response.delta') {
                    transcriptEl.textContent = data.delta?.content || data.delta?.text || JSON.stringify(data.delta);
                } else if (data.type === 'transcript.delta') {
                    transcriptEl.textContent = data.delta?.text || transcriptEl.textContent;
                }
            } catch (e) {
                transcriptEl.textContent = evt.data;
            }
        };

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const model = encodeURIComponent('gpt-4o-realtime-preview-2024-12-17');
        let answerSdp;

        // Ensure sending SDP in correct content type
        const r = await fetch(`${realtimeUrl}?model=${model}`, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${ephemeralKey}`,
                'Content-Type': 'application/sdp'
            },
            body: pc.localDescription.sdp
        });

        if (!r.ok) throw new Error('Failed to get SDP');
        answerSdp = await r.text();

        await pc.setRemoteDescription({ type: 'answer', sdp: answerSdp });
        statusEl.textContent = 'කතාබස් සක්‍රීයයි';
    } catch (err) {
        console.error(err);
        statusEl.textContent = 'සම්බන්ධතාවය අසාර්ථකයි';
        micActive = false;
        micButton.classList.remove('active');
    }
}

function stopCall() {
    micActive = false;
    if (pc) { pc.getSenders().forEach(s => s.track?.stop()); pc.close(); pc = null; }
    if (localStream) { localStream.getTracks().forEach(t => t.stop()); localStream = null; }
    ephemeralKey = null;
    assistantAudio.srcObject = null;
    statusEl.textContent = 'වෙළඳාම නැවත සක්‍රීයයි';
    transcriptEl.textContent = 'කතා අසනවා...';
}

window.addEventListener('beforeunload', () => { stopCall(); });